name: "Complex Classification Evaluation Set"
description: "Challenging evaluation set with longer, ambiguous text for the three labels in intent_classification.yaml"
classification_type: "single"
examples:
  - text: "I've been thinking about machine learning algorithms quite a bit lately, especially how neural networks can mimic human cognition to some extent. Could you explain to me the fundamental differences between supervised and unsupervised learning paradigms, and why one might be more suitable than the other for certain types of problems? I'm particularly interested in understanding how these approaches handle unlabeled data."
    expected_label: "question"
  
  - text: "In a world increasingly dominated by artificial intelligence, I find myself wondering about the ethical implications of autonomous systems making decisions that affect human lives. What are the most important considerations we should be making as we develop more advanced AI systems, and how can we ensure they align with human values and priorities? Are there particular philosophical frameworks that you think are most useful for addressing these questions?"
    expected_label: "question"
  
  - text: "I've been working with some complex datasets recently and noticed something interesting. When I analyze the distribution of values across different demographic groups, there seems to be a pattern that I can't quite make sense of. Is there a statistical approach I should be using to determine whether these apparent patterns are significant or just random noise? I'm not very experienced with advanced statistical methods and would appreciate some guidance."
    expected_label: "question"
  
  - text: "Looking at my calendar for the next few weeks, I realize I need to coordinate several important meetings with my team regarding the quarterly product review. Could you help me find suitable time slots that accommodate everyone's availability, ensuring that we have sufficient time to cover all the agenda items? I need to schedule three separate sessions: one for the engineering team on Tuesday or Wednesday afternoon, another for the marketing team preferably on Thursday morning, and a final all-hands session that everyone must attend, ideally on Friday before lunch."
    expected_label: "scheduling"
  
  - text: "I need to organize a series of professional development workshops for my department in the coming month. The first workshop should be scheduled for approximately three hours on either Monday or Wednesday of next week, and we'll need a meeting room with projection capabilities. The second workshop should be two weeks later, preferably in the afternoon. Finally, I'd like to arrange a follow-up session toward the end of the month to review what we've learned. Could you help me coordinate these events and send out calendar invitations to all fifteen team members once we've confirmed the dates?"
    expected_label: "scheduling"
  
  - text: "Our project timeline is getting quite tight, and I need to rearrange several upcoming meetings to ensure we meet our deadlines. The client presentation that was originally set for next Tuesday at 2 PM needs to be moved to Thursday at the same time. Additionally, I need to schedule two new review sessions with the design team - one focused on UI elements and another on backend architecture. Both should be at least 90 minutes long and take place before the client presentation. Could you also block off three hours on Friday afternoon for our team to incorporate any feedback we receive from these sessions?"
    expected_label: "scheduling"
  
  - text: "I'm developing a web application that needs to process and analyze large sets of user interaction data in real-time. The current implementation uses a simple array-based approach, but it's becoming inefficient as our user base grows. I need to implement a more scalable solution that can handle concurrent operations efficiently. Could you help me develop a proper algorithm that uses an appropriate data structure like a B-tree or hash map to optimize these operations? The solution needs to maintain O(log n) time complexity for lookups and insertions even as the dataset grows significantly."
    expected_label: "coding"
  
  - text: "I've been trying to implement an authentication system for my application using JSON Web Tokens, but I'm encountering some issues with token validation and refresh logic. When a user logs in, I generate a token pair (access and refresh tokens), but I'm not sure how to properly handle token expiration and renewal without creating security vulnerabilities. Could you help me implement a robust JWT authentication flow in Node.js with Express, ensuring that we're following security best practices for token storage, validation, and renewal? I'm particularly concerned about protecting against token hijacking and replay attacks."
    expected_label: "coding"
  
  - text: "My Python script for data analysis is running extremely slowly when processing larger datasets. Currently, it reads a CSV file with millions of records, performs several transformations on each record, and then aggregates the results. The main bottleneck seems to be in the transformation step, where I'm using nested loops and string operations. I've considered using NumPy or Pandas, but I'm not sure how to restructure my code to leverage these libraries effectively. Could you help me optimize this script to improve its performance, possibly using vectorization, multiprocessing, or other techniques that would make it more efficient?"
    expected_label: "coding"
  
  # Ambiguous examples that combine multiple intents
  - text: "I'm building a scheduling application that needs to efficiently handle thousands of calendar events with complex recurrence patterns. The current algorithm I'm using works for basic cases, but fails when dealing with exceptions to recurring events or timezone conversions. What's the most efficient data structure and algorithm approach for implementing a robust calendar system that can quickly retrieve all events for a given time range while properly handling recurring events? I'm particularly interested in how to structure the database schema and query optimization techniques."
    expected_label: "coding"  # Ambiguous between coding and question
  
  - text: "As part of my role managing our team's development process, I need to schedule several code review sessions for our new feature release. The first session should focus on the front-end components and needs to be scheduled sometime next week, preferably in the morning when our UI developers are most productive. The second session should cover the API implementation and database models, which would be best held in the afternoon when our backend team is available. Each session needs to be at least two hours long, and we should make sure to record them for team members who can't attend. Could you help me organize these meetings?"
    expected_label: "scheduling"  # Ambiguous between scheduling and coding
  
  - text: "I've been reading about different approaches to implementing efficient scheduling algorithms in distributed systems. For a project I'm working on, I need to develop a job scheduler that can intelligently allocate computing resources across multiple nodes while accounting for dependencies between tasks. Could you explain the theoretical foundations of scheduling algorithms like Rate Monotonic and Earliest Deadline First, and how they might be implemented in a distributed environment? I'm also interested in understanding how modern container orchestration systems like Kubernetes handle scheduling decisions internally."
    expected_label: "question"  # Highly ambiguous between question, coding, and scheduling
    
  - text: "Our development team is facing challenges with our current sprint schedule, and I think we need to restructure our approach to accommodate more complex user stories. Could you help me devise a more efficient sprint planning methodology that incorporates adequate time for code reviews and testing? I'm thinking we should schedule longer planning sessions at the beginning of each sprint, followed by daily stand-ups that actually focus on blockers rather than status updates. We also need dedicated time for addressing technical debt, which we've been neglecting. How would you recommend we restructure our development calendar to optimize productivity while maintaining code quality?"
    expected_label: "scheduling"  # Ambiguous between scheduling and coding
    
  - text: "I've been tasked with developing a scheduling algorithm for our company's employee shift management system. The algorithm needs to account for various constraints like employee availability, required skills for each shift, legal restrictions on consecutive working hours, and fair distribution of weekend and holiday shifts. I've started implementing a constraint satisfaction approach in Python, but I'm running into performance issues when trying to optimize schedules for more than 50 employees. Could you help me design a more efficient algorithm, perhaps using operations research techniques or heuristic methods? I'd appreciate some code examples showing how to structure the core optimization function."
    expected_label: "coding"  # Ambiguous between coding and scheduling
    
  - text: "I'm interested in understanding the mathematical principles behind modern scheduling algorithms used in operating systems. Specifically, how do techniques like multilevel feedback queues balance response time and throughput? What are the theoretical bounds on scheduling efficiency when dealing with processes that have variable burst times and priorities? I'm working on a research paper comparing traditional approaches with newer methods that incorporate machine learning to predict process behavior, and I need to build a solid theoretical foundation before implementing experimental benchmarks."
    expected_label: "question"

  # Additional nuanced examples with increasing complexity and difficulty
  - text: |
      Our analytics pipeline is currently performing inconsistent load balancing when tasks exceed a certain threshold. Specifically, job shards on node A sometimes process in less than half the time of identical shards on node B. We've tried tuning our Kafka consumer groups and explored adjusting the partition assignment strategy, but none have yielded satisfactory results. We also observed that shifting resource allocation between CPU and I/O-intensive operations had minimal impact on end-to-end latency under peak traffic. We're particularly concerned about the interaction between our custom scheduling service and the container orchestrator's default resource scheduler. Could you help diagnose the root cause and suggest systematic ways to benchmark and profile the pipeline under variable load, including tools for tracing distributed segments and correlating them with resource utilization logs?
    expected_label: "coding"

  - text: |
      We need to schedule a series of cross-departmental workshops for the upcoming quarter. The first workshop focuses on data privacy and compliance, requiring a minimum of two hours and must accommodate attendees across three time zones (EST, GMT, PST). We need to ensure real-time dial-in links are provisioned for remote participants and that local venues have appropriate AV setups. The second is an all-hands retrospective session slated for the last Friday of each month, but staff have requested morning slots due to end-of-week commitments and childcare considerations. For that session, we also need breakout rooms for smaller teams to discuss actionable items. Finally, we plan a quarterly strategy meeting combining in-person and remote participants from five different departments. We need to identify overlapping windows across PST, CET, and IST time zones, reserve a hybrid conference room, and distribute pre-meeting reading materials. Can you propose a detailed schedule and resource plan that meets these constraints, including fallback slots in case of room unavailability?
    expected_label: "scheduling"

  - text: |
      Could you explain the trade-offs inherent in the CAP theorem for distributed databases, and how these trade-offs influence design choices when architecting geo-replicated systems? I'd like to understand not only the theoretical underpinnings of Consistency, Availability, and Partition tolerance, but also practical limits in networks with variable latency and regional outages. Please include real-world case studies—such as how Amazon's DynamoDB manages eventual consistency across multiple regions, and how Facebook's TAO handles stale reads at scale. It would be helpful to learn about specific developer patterns or middleware used to detect and resolve anomalies, as well as metrics for measuring convergence times and conflict rates in eventual consistency scenarios.
    expected_label: "question"

  - text: |
      Our QA process requires nightly regression test runs across five different environments, but the current pipeline overlaps tests and causes resource contention. We're using Jenkins pipelines triggered by Git tags for builds, and each environment has finite container instances, often leading to queue backlogs. We need to allocate test environments efficiently, schedule build jobs to minimize idle time, and assign engineers to monitor failures. Additionally, we'd like to integrate parallel execution for critical smoke tests, set up notifications via email and Slack threads segmented by service area, and capture performance metrics after each run. Can you help design an optimized testing schedule that uses staggered start times, environment pools, and dynamic scaling policies so that it scales predictably as we add more microservices to the suite?
    expected_label: "scheduling"

  - text: |
      I'm implementing a Proximal Policy Optimization (PPO) reinforcement learning algorithm in a robotics control system. The policy network must handle continuous action spaces and constrain exploration to within safe operational bounds to avoid potential hardware damage. We also need to incorporate a safety layer using constraint-satisfying filters at inference time. Could you provide detailed Python code examples for integrating gradient clipping with a dynamic clipping coefficient, advantage normalization across mini-batches, and asynchronous parallel environment sampling using vectorized Gym environments? Additionally, please include best practices for tuning hyperparameters like clip epsilon, learning rates, and batch sizes to stabilize training, as well as suggestions for logging and monitoring reward distributions during long training runs.
    expected_label: "coding"

  - text: |
      I'm designing an A/B testing platform with multi-armed bandit capabilities to optimize feature rollouts in real time. We need to support both frequentist and Bayesian methods, include posterior sampling strategies like Thompson Sampling, and ensure proper confidence intervals for sequential tests. How can I ensure statistical validity when using sequential testing, control the false discovery rate in multi-test scenarios, and dynamically adjust traffic allocation based on early signals without introducing sampling bias? Please discuss methods for implementing corrections like alpha-spending functions, analyze the trade-offs between ε-greedy and cost-sensitive bandits, and suggest libraries or frameworks that facilitate these approaches at scale.
    expected_label: "question"

  - text: |
      We are planning a phased CI/CD pipeline rollout across our microservices fleet. The deployment sequence should go from development to staging to production, with maintenance windows no longer than 30 minutes each night, and blue-green deployment strategies where possible. We need to coordinate with the on-call rotation to ensure overlap with each maintenance window, notify stakeholders via Slack and email, and include automated rollback procedures triggered by health-check failures. Additionally, we want to integrate pre-deployment smoke tests and post-deployment canary analysis with real-time dashboards. Can you draft a detailed deployment and communication schedule that meets these requirements, including notification timing, runbook references, and escalation paths?
    expected_label: "scheduling"

  - text: |
      Our deep learning team wants to optimize training of a transformer-based NLP model across 8 GPUs using PyTorch Distributed Data Parallel (DDP). We need to implement mixed precision training with torch.cuda.amp, gradient accumulation to handle large effective batch sizes that exceed GPU memory, and efficient inter-GPU communication via NCCL all-reduce operations. Could you suggest Python code patterns that include optimizer wrappers like Apex or native PyTorch solutions, demonstrate how to integrate gradient scaling, and outline strategies for overlapping communication and computation to achieve near-linear scaling? Please include command-line examples for launching distributed jobs, resource utilization monitoring tips, and troubleshooting advice for common DDP errors.
    expected_label: "coding"